{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30427054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, classification_report, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7685490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset details\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"wisconsin data\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\wisconsin data.csv\",\n",
    "        \"features_numerical\": [\n",
    "            \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \n",
    "            \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \n",
    "            \"fractal_dimension_mean\", \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \n",
    "            \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \n",
    "            \"fractal_dimension_se\", \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \n",
    "            \"area_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \n",
    "            \"concave points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\"\n",
    "        ],\n",
    "        \"features_categorical\": [],\n",
    "        \"target\": \"diagnosis\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"breast-cancer-dataset\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\breast-cancer-dataset.csv\",\n",
    "        \"features_numerical\": [\"Year\", \"Age\", \"Tumor Size (cm)\", \"Inv-Nodes\"],\n",
    "        \"features_categorical\": [\"Menopause\", \"Breast\", \"Metastasis\", \"Breast Quadrant\", \"History\"],\n",
    "        \"target\": \"Diagnosis Result\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BRCA\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\BRCA.csv\",\n",
    "        \"features_numerical\": [\"Age\", \"Protein1\", \"Protein2\", \"Protein3\", \"Protein4\"],\n",
    "        \"features_categorical\": [\"Gender\", \"Tumour_Stage\", \"Histology\", \"ER status\", \"PR status\", \"HER2 status\", \"Surgery_type\"],\n",
    "        \"target\": \"Patient_Status\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"german bs data\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\german bs data.csv\",\n",
    "        \"features_numerical\": [\"age\", \"size\", \"grade\", \"nodes\", \"pgr\", \"er\", \"rfstime\"],\n",
    "        \"features_categorical\": [\"meno\", \"hormon\"],\n",
    "        \"target\": \"status\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"seer data\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\seer data.csv\",\n",
    "        \"features_numerical\": [\"Age\", \"Survival Months\", \"Regional Node Examined\"],\n",
    "        \"features_categorical\": [\n",
    "            \"Race\", \"Marital Status\", \"T Stage \", \"N Stage\", \"6th Stage\", \"differentiate\", \n",
    "            \"Grade\", \"A Stage\", \"Tumor Size\", \"Estrogen Status\", \"Progesterone Status\", \n",
    "            \"Reginol Node Positive\"\n",
    "        ],\n",
    "        \"target\": \"Status\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e920c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    print(f\"Processing dataset: {dataset['name']}\")\n",
    "    df = pd.read_csv(dataset['path'])\n",
    "    \n",
    "    # Verify that all specified columns exist in the dataset\n",
    "    missing_numerical = [col for col in dataset[\"features_numerical\"] if col not in df.columns]\n",
    "    missing_categorical = [col for col in dataset[\"features_categorical\"] if col not in df.columns]\n",
    "    \n",
    "    if missing_numerical or missing_categorical:\n",
    "        raise ValueError(\n",
    "            f\"Missing columns in dataset {dataset['name']}: \"\n",
    "            f\"Numerical: {missing_numerical}, Categorical: {missing_categorical}\"\n",
    "        )\n",
    "    \n",
    "    # Clean numerical columns: replace non-numeric values with NaN\n",
    "    for col in dataset[\"features_numerical\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, invalid values become NaN\n",
    "    \n",
    "    # Drop rows with missing values in numerical columns\n",
    "    df.dropna(subset=dataset[\"features_numerical\"], inplace=True)\n",
    "    \n",
    "    # Extract numerical and categorical features\n",
    "    X_num = df[dataset[\"features_numerical\"]]\n",
    "    X_cat = df[dataset[\"features_categorical\"]] if dataset[\"features_categorical\"] else pd.DataFrame()\n",
    "    y = df[dataset[\"target\"]]\n",
    "\n",
    "    # Encode categorical variables if they exist\n",
    "    if not X_cat.empty:\n",
    "        X_cat = pd.get_dummies(X_cat, drop_first=True)\n",
    "    \n",
    "    # Encode target variable if it's categorical\n",
    "    if y.dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "\n",
    "    # Combine features\n",
    "    X = pd.concat([X_num, X_cat], axis=1) if not X_cat.empty else X_num\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # Scale numerical features (keeping them as DataFrames)\n",
    "    scaler = StandardScaler()\n",
    "    X_train[dataset[\"features_numerical\"]] = scaler.fit_transform(X_train[dataset[\"features_numerical\"]])\n",
    "    X_test[dataset[\"features_numerical\"]] = scaler.transform(X_test[dataset[\"features_numerical\"]])\n",
    "\n",
    "    # Convert all data to float32 for TensorFlow compatibility\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_test = y_test.astype(np.float32)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49efe02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neural_network(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='categorical_crossentropy' if num_classes > 1 else 'binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bdb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_class_imbalance(X_train, y_train):\n",
    "    # Apply SMOTE for oversampling\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    return X_train_resampled, y_train_resampled, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e14da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training on dataset: wisconsin data\n",
      "==================================================\n",
      "Processing dataset: wisconsin data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.7241 - loss: 0.5301 - val_accuracy: 0.8800 - val_loss: 0.3127\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9284 - loss: 0.2441 - val_accuracy: 0.9100 - val_loss: 0.2035\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9307 - loss: 0.1722 - val_accuracy: 0.9700 - val_loss: 0.1007\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9776 - loss: 0.0874 - val_accuracy: 0.9800 - val_loss: 0.0630\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9756 - loss: 0.0837 - val_accuracy: 0.9800 - val_loss: 0.0482\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9880 - loss: 0.0726 - val_accuracy: 0.9800 - val_loss: 0.0407\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9760 - loss: 0.0782 - val_accuracy: 0.9800 - val_loss: 0.0359\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9814 - loss: 0.0558 - val_accuracy: 0.9800 - val_loss: 0.0303\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9772 - loss: 0.0592 - val_accuracy: 0.9800 - val_loss: 0.0289\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9897 - loss: 0.0498 - val_accuracy: 0.9900 - val_loss: 0.0157\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9825 - loss: 0.0630 - val_accuracy: 0.9900 - val_loss: 0.0177\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0372 - val_accuracy: 0.9900 - val_loss: 0.0166\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9771 - loss: 0.0647 - val_accuracy: 0.9900 - val_loss: 0.0140\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0469 - val_accuracy: 0.9900 - val_loss: 0.0110\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9751 - loss: 0.0732 - val_accuracy: 0.9900 - val_loss: 0.0120\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9844 - loss: 0.0385 - val_accuracy: 0.9900 - val_loss: 0.0129\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9873 - loss: 0.0390 - val_accuracy: 0.9900 - val_loss: 0.0125\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9882 - loss: 0.0350 - val_accuracy: 0.9900 - val_loss: 0.0103\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9832 - loss: 0.0353 - val_accuracy: 0.9900 - val_loss: 0.0089\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9973 - loss: 0.0157 - val_accuracy: 0.9900 - val_loss: 0.0093\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9953 - loss: 0.0243 - val_accuracy: 0.9900 - val_loss: 0.0073\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9907 - loss: 0.0271 - val_accuracy: 1.0000 - val_loss: 0.0044\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9774 - loss: 0.0464 - val_accuracy: 0.9900 - val_loss: 0.0072\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9866 - loss: 0.0275 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9917 - loss: 0.0188 - val_accuracy: 1.0000 - val_loss: 0.0056\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9918 - loss: 0.0268 - val_accuracy: 1.0000 - val_loss: 0.0036\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9885 - loss: 0.0225 - val_accuracy: 1.0000 - val_loss: 0.0029\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9949 - loss: 0.0137 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 0.0023\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9976 - loss: 0.0117 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.0098 - val_accuracy: 1.0000 - val_loss: 0.0021\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9882 - loss: 0.0240 - val_accuracy: 1.0000 - val_loss: 0.0018\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9948 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9833 - loss: 0.0261 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9978 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9949 - loss: 0.0119 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 7.5339e-04\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9982 - loss: 0.0095 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9987 - loss: 0.0093 - val_accuracy: 1.0000 - val_loss: 0.0015\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9955 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 8.6806e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0059 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9989 - loss: 0.0078 - val_accuracy: 1.0000 - val_loss: 9.5733e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9914 - loss: 0.0195 - val_accuracy: 1.0000 - val_loss: 8.1344e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0041 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0108 - val_accuracy: 1.0000 - val_loss: 7.8501e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9961 - loss: 0.0132 - val_accuracy: 1.0000 - val_loss: 4.0802e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0050 - val_accuracy: 1.0000 - val_loss: 5.4247e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9985 - loss: 0.0048 - val_accuracy: 1.0000 - val_loss: 4.0158e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9961 - loss: 0.0066 - val_accuracy: 1.0000 - val_loss: 3.0796e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9927 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 3.7281e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Model Accuracy: 0.9707602339181286\n",
      "ROC-AUC: 0.9945969626168225\n",
      "\n",
      "==================================================\n",
      "Training on dataset: breast-cancer-dataset\n",
      "==================================================\n",
      "Processing dataset: breast-cancer-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 159ms/step - accuracy: 0.4247 - loss: 0.7301 - val_accuracy: 0.8235 - val_loss: 0.5882\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6040 - loss: 0.6482 - val_accuracy: 0.7941 - val_loss: 0.5666\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.7857 - loss: 0.5943 - val_accuracy: 0.8235 - val_loss: 0.5301\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8899 - loss: 0.5224 - val_accuracy: 0.8235 - val_loss: 0.4931\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8975 - loss: 0.4661 - val_accuracy: 0.8235 - val_loss: 0.4632\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9050 - loss: 0.4174 - val_accuracy: 0.8529 - val_loss: 0.4530\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9163 - loss: 0.3247 - val_accuracy: 0.8235 - val_loss: 0.4632\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8567 - loss: 0.3451 - val_accuracy: 0.8235 - val_loss: 0.4831\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9272 - loss: 0.2783 - val_accuracy: 0.8529 - val_loss: 0.5103\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9284 - loss: 0.2387 - val_accuracy: 0.8529 - val_loss: 0.4846\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9284 - loss: 0.2224 - val_accuracy: 0.8235 - val_loss: 0.4569\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9086 - loss: 0.2297 - val_accuracy: 0.8235 - val_loss: 0.4533\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9262 - loss: 0.2204 - val_accuracy: 0.8235 - val_loss: 0.4569\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9451 - loss: 0.2422 - val_accuracy: 0.8529 - val_loss: 0.4611\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9322 - loss: 0.2283 - val_accuracy: 0.8529 - val_loss: 0.4459\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9513 - loss: 0.1779 - val_accuracy: 0.8529 - val_loss: 0.4202\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9314 - loss: 0.2254 - val_accuracy: 0.8529 - val_loss: 0.3941\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9324 - loss: 0.1995 - val_accuracy: 0.8529 - val_loss: 0.3473\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9294 - loss: 0.2061 - val_accuracy: 0.8529 - val_loss: 0.3421\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9186 - loss: 0.2378 - val_accuracy: 0.8529 - val_loss: 0.3530\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9219 - loss: 0.1805 - val_accuracy: 0.8529 - val_loss: 0.3802\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9041 - loss: 0.2144 - val_accuracy: 0.8529 - val_loss: 0.3872\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9129 - loss: 0.2032 - val_accuracy: 0.8235 - val_loss: 0.3801\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9088 - loss: 0.1982 - val_accuracy: 0.8235 - val_loss: 0.3570\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8964 - loss: 0.2086 - val_accuracy: 0.8529 - val_loss: 0.3186\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9081 - loss: 0.2107 - val_accuracy: 0.8824 - val_loss: 0.2915\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9584 - loss: 0.1613 - val_accuracy: 0.8824 - val_loss: 0.2895\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9267 - loss: 0.2146 - val_accuracy: 0.9118 - val_loss: 0.2649\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9626 - loss: 0.1382 - val_accuracy: 0.9412 - val_loss: 0.2370\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9442 - loss: 0.1586 - val_accuracy: 0.9412 - val_loss: 0.2282\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9490 - loss: 0.1442 - val_accuracy: 0.9412 - val_loss: 0.2222\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9510 - loss: 0.1817 - val_accuracy: 0.9412 - val_loss: 0.2144\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9686 - loss: 0.1371 - val_accuracy: 0.9118 - val_loss: 0.2325\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9519 - loss: 0.1642 - val_accuracy: 0.9118 - val_loss: 0.2354\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9206 - loss: 0.1783 - val_accuracy: 0.9118 - val_loss: 0.2226\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9483 - loss: 0.1605 - val_accuracy: 0.9118 - val_loss: 0.2224\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9298 - loss: 0.1765 - val_accuracy: 0.9118 - val_loss: 0.2229\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9600 - loss: 0.1242 - val_accuracy: 0.9118 - val_loss: 0.2324\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9118 - loss: 0.1681 - val_accuracy: 0.9118 - val_loss: 0.2390\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9293 - loss: 0.1720 - val_accuracy: 0.9118 - val_loss: 0.2378\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9655 - loss: 0.1459 - val_accuracy: 0.9118 - val_loss: 0.2241\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9680 - loss: 0.1307 - val_accuracy: 0.9118 - val_loss: 0.2097\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9496 - loss: 0.1477 - val_accuracy: 0.9118 - val_loss: 0.1991\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9660 - loss: 0.1138 - val_accuracy: 0.9118 - val_loss: 0.1955\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9370 - loss: 0.1308 - val_accuracy: 0.9118 - val_loss: 0.1991\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9508 - loss: 0.1726 - val_accuracy: 0.9118 - val_loss: 0.2134\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9732 - loss: 0.1117 - val_accuracy: 0.9118 - val_loss: 0.2147\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9063 - loss: 0.1668 - val_accuracy: 0.9118 - val_loss: 0.2040\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9666 - loss: 0.1380 - val_accuracy: 0.9118 - val_loss: 0.2022\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9582 - loss: 0.1192 - val_accuracy: 0.9118 - val_loss: 0.2018\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step \n",
      "Model Accuracy: 0.890625\n",
      "ROC-AUC: 0.9623015873015872\n",
      "\n",
      "==================================================\n",
      "Training on dataset: BRCA\n",
      "==================================================\n",
      "Processing dataset: BRCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 57ms/step - accuracy: 0.4249 - loss: 1.0840 - val_accuracy: 0.0000e+00 - val_loss: 1.3117\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4602 - loss: 1.0193 - val_accuracy: 0.0000e+00 - val_loss: 1.4610\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5179 - loss: 0.9866 - val_accuracy: 0.0000e+00 - val_loss: 1.5087\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5356 - loss: 0.9494 - val_accuracy: 0.0000e+00 - val_loss: 1.4759\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5484 - loss: 0.9046 - val_accuracy: 0.0000e+00 - val_loss: 1.5069\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4878 - loss: 0.9357 - val_accuracy: 0.0000e+00 - val_loss: 1.4245\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5382 - loss: 0.8968 - val_accuracy: 0.0000e+00 - val_loss: 1.3495\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5786 - loss: 0.8489 - val_accuracy: 0.0187 - val_loss: 1.3008\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5611 - loss: 0.8299 - val_accuracy: 0.0748 - val_loss: 1.2598\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6516 - loss: 0.7877 - val_accuracy: 0.2336 - val_loss: 1.1934\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6176 - loss: 0.8089 - val_accuracy: 0.3271 - val_loss: 1.1789\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6651 - loss: 0.7349 - val_accuracy: 0.4486 - val_loss: 1.1355\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6416 - loss: 0.7623 - val_accuracy: 0.6729 - val_loss: 0.9343\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6911 - loss: 0.7156 - val_accuracy: 0.6822 - val_loss: 0.8905\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6503 - loss: 0.7382 - val_accuracy: 0.6636 - val_loss: 0.8559\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7321 - loss: 0.6501 - val_accuracy: 0.6916 - val_loss: 0.8127\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7062 - loss: 0.6329 - val_accuracy: 0.7477 - val_loss: 0.6919\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7660 - loss: 0.5835 - val_accuracy: 0.7757 - val_loss: 0.6448\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7350 - loss: 0.6050 - val_accuracy: 0.7664 - val_loss: 0.6247\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7428 - loss: 0.5978 - val_accuracy: 0.8037 - val_loss: 0.5526\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8051 - loss: 0.4937 - val_accuracy: 0.8224 - val_loss: 0.4781\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7835 - loss: 0.5413 - val_accuracy: 0.8972 - val_loss: 0.3715\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7978 - loss: 0.5166 - val_accuracy: 0.8785 - val_loss: 0.4135\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8010 - loss: 0.4784 - val_accuracy: 0.9159 - val_loss: 0.2823\n",
      "Epoch 25/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7996 - loss: 0.4845 - val_accuracy: 0.9252 - val_loss: 0.2504\n",
      "Epoch 26/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7725 - loss: 0.4914 - val_accuracy: 0.9159 - val_loss: 0.2597\n",
      "Epoch 27/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8496 - loss: 0.4134 - val_accuracy: 0.9533 - val_loss: 0.2028\n",
      "Epoch 28/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8539 - loss: 0.4219 - val_accuracy: 0.9346 - val_loss: 0.2225\n",
      "Epoch 29/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8053 - loss: 0.4456 - val_accuracy: 0.9720 - val_loss: 0.1699\n",
      "Epoch 30/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8673 - loss: 0.3950 - val_accuracy: 0.9720 - val_loss: 0.1425\n",
      "Epoch 31/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8115 - loss: 0.4110 - val_accuracy: 0.9439 - val_loss: 0.1770\n",
      "Epoch 32/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8799 - loss: 0.3608 - val_accuracy: 1.0000 - val_loss: 0.1112\n",
      "Epoch 33/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8911 - loss: 0.3212 - val_accuracy: 1.0000 - val_loss: 0.1243\n",
      "Epoch 34/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8422 - loss: 0.3827 - val_accuracy: 1.0000 - val_loss: 0.0990\n",
      "Epoch 35/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8826 - loss: 0.3169 - val_accuracy: 0.9907 - val_loss: 0.1103\n",
      "Epoch 36/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8587 - loss: 0.3755 - val_accuracy: 1.0000 - val_loss: 0.0859\n",
      "Epoch 37/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8721 - loss: 0.3420 - val_accuracy: 0.9907 - val_loss: 0.1099\n",
      "Epoch 38/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8552 - loss: 0.3623 - val_accuracy: 0.9907 - val_loss: 0.0874\n",
      "Epoch 39/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9177 - loss: 0.2509 - val_accuracy: 1.0000 - val_loss: 0.0682\n",
      "Epoch 40/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8509 - loss: 0.3201 - val_accuracy: 1.0000 - val_loss: 0.0849\n",
      "Epoch 41/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9068 - loss: 0.2706 - val_accuracy: 1.0000 - val_loss: 0.0814\n",
      "Epoch 42/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8982 - loss: 0.2889 - val_accuracy: 1.0000 - val_loss: 0.0485\n",
      "Epoch 43/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8601 - loss: 0.3419 - val_accuracy: 1.0000 - val_loss: 0.0699\n",
      "Epoch 44/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8872 - loss: 0.2929 - val_accuracy: 1.0000 - val_loss: 0.0523\n",
      "Epoch 45/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8827 - loss: 0.2840 - val_accuracy: 1.0000 - val_loss: 0.0590\n",
      "Epoch 46/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8920 - loss: 0.2535 - val_accuracy: 1.0000 - val_loss: 0.0496\n",
      "Epoch 47/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9072 - loss: 0.2702 - val_accuracy: 1.0000 - val_loss: 0.0528\n",
      "Epoch 48/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9139 - loss: 0.2620 - val_accuracy: 1.0000 - val_loss: 0.0443\n",
      "Epoch 49/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9318 - loss: 0.2043 - val_accuracy: 1.0000 - val_loss: 0.0532\n",
      "Epoch 50/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8954 - loss: 0.2463 - val_accuracy: 1.0000 - val_loss: 0.0318\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 154ms/stepWARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000264B5FFC400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "Model Accuracy: 0.6237623762376238\n",
      "ROC-AUC: 0.5337270983684852\n",
      "\n",
      "==================================================\n",
      "Training on dataset: german bs data\n",
      "==================================================\n",
      "Processing dataset: german bs data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.4571 - loss: 0.7312 - val_accuracy: 0.5046 - val_loss: 0.7001\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6451 - loss: 0.6407 - val_accuracy: 0.5963 - val_loss: 0.6542\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6955 - loss: 0.6023 - val_accuracy: 0.6422 - val_loss: 0.6098\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6906 - loss: 0.5988 - val_accuracy: 0.6697 - val_loss: 0.5777\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6946 - loss: 0.5837 - val_accuracy: 0.6881 - val_loss: 0.5770\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7468 - loss: 0.5709 - val_accuracy: 0.6972 - val_loss: 0.5855\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7720 - loss: 0.5244 - val_accuracy: 0.6972 - val_loss: 0.5820\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6831 - loss: 0.5755 - val_accuracy: 0.7156 - val_loss: 0.5365\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7356 - loss: 0.5542 - val_accuracy: 0.7156 - val_loss: 0.5572\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7848 - loss: 0.5099 - val_accuracy: 0.7156 - val_loss: 0.5590\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7355 - loss: 0.5321 - val_accuracy: 0.7156 - val_loss: 0.5525\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7087 - loss: 0.5353 - val_accuracy: 0.7248 - val_loss: 0.5380\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7728 - loss: 0.5059 - val_accuracy: 0.7248 - val_loss: 0.5383\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7541 - loss: 0.5140 - val_accuracy: 0.7248 - val_loss: 0.5309\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7608 - loss: 0.4994 - val_accuracy: 0.7248 - val_loss: 0.5445\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7633 - loss: 0.4900 - val_accuracy: 0.7248 - val_loss: 0.5331\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7689 - loss: 0.4711 - val_accuracy: 0.7248 - val_loss: 0.5237\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7401 - loss: 0.5064 - val_accuracy: 0.7156 - val_loss: 0.5365\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7757 - loss: 0.4967 - val_accuracy: 0.7431 - val_loss: 0.5241\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7263 - loss: 0.5119 - val_accuracy: 0.7248 - val_loss: 0.5338\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7878 - loss: 0.4815 - val_accuracy: 0.7248 - val_loss: 0.5416\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7822 - loss: 0.4806 - val_accuracy: 0.7431 - val_loss: 0.5210\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7636 - loss: 0.5117 - val_accuracy: 0.7523 - val_loss: 0.5010\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7678 - loss: 0.4751 - val_accuracy: 0.7156 - val_loss: 0.5371\n",
      "Epoch 25/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7835 - loss: 0.4605 - val_accuracy: 0.7248 - val_loss: 0.5277\n",
      "Epoch 26/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7435 - loss: 0.5040 - val_accuracy: 0.7523 - val_loss: 0.5128\n",
      "Epoch 27/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7830 - loss: 0.4578 - val_accuracy: 0.7248 - val_loss: 0.5198\n",
      "Epoch 28/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7553 - loss: 0.5319 - val_accuracy: 0.7431 - val_loss: 0.5099\n",
      "Epoch 29/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7914 - loss: 0.4871 - val_accuracy: 0.7064 - val_loss: 0.5446\n",
      "Epoch 30/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7664 - loss: 0.5081 - val_accuracy: 0.7339 - val_loss: 0.5108\n",
      "Epoch 31/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7819 - loss: 0.4626 - val_accuracy: 0.7248 - val_loss: 0.5092\n",
      "Epoch 32/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7485 - loss: 0.4857 - val_accuracy: 0.7615 - val_loss: 0.4911\n",
      "Epoch 33/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7848 - loss: 0.4676 - val_accuracy: 0.7431 - val_loss: 0.4998\n",
      "Epoch 34/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7737 - loss: 0.4663 - val_accuracy: 0.7431 - val_loss: 0.4978\n",
      "Epoch 35/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7815 - loss: 0.4799 - val_accuracy: 0.7431 - val_loss: 0.5067\n",
      "Epoch 36/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7065 - loss: 0.5340 - val_accuracy: 0.7339 - val_loss: 0.4900\n",
      "Epoch 37/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7801 - loss: 0.4831 - val_accuracy: 0.7248 - val_loss: 0.5146\n",
      "Epoch 38/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7773 - loss: 0.4531 - val_accuracy: 0.7248 - val_loss: 0.4965\n",
      "Epoch 39/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7568 - loss: 0.4687 - val_accuracy: 0.7431 - val_loss: 0.4835\n",
      "Epoch 40/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7464 - loss: 0.4906 - val_accuracy: 0.7431 - val_loss: 0.5002\n",
      "Epoch 41/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7620 - loss: 0.4800 - val_accuracy: 0.7339 - val_loss: 0.4965\n",
      "Epoch 42/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7840 - loss: 0.4946 - val_accuracy: 0.7431 - val_loss: 0.4958\n",
      "Epoch 43/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7705 - loss: 0.4591 - val_accuracy: 0.7248 - val_loss: 0.5032\n",
      "Epoch 44/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7892 - loss: 0.4630 - val_accuracy: 0.7431 - val_loss: 0.4756\n",
      "Epoch 45/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7641 - loss: 0.4748 - val_accuracy: 0.7523 - val_loss: 0.4885\n",
      "Epoch 46/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7761 - loss: 0.4553 - val_accuracy: 0.7339 - val_loss: 0.4883\n",
      "Epoch 47/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7725 - loss: 0.4692 - val_accuracy: 0.7523 - val_loss: 0.5167\n",
      "Epoch 48/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7949 - loss: 0.4461 - val_accuracy: 0.7431 - val_loss: 0.5183\n",
      "Epoch 49/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7937 - loss: 0.4543 - val_accuracy: 0.7615 - val_loss: 0.4641\n",
      "Epoch 50/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8022 - loss: 0.4622 - val_accuracy: 0.7615 - val_loss: 0.4796\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x00000264B6256340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n",
      "Model Accuracy: 0.6893203883495146\n",
      "ROC-AUC: 0.7433908045977011\n",
      "\n",
      "==================================================\n",
      "Training on dataset: seer data\n",
      "==================================================\n",
      "Processing dataset: seer data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 10ms/step - accuracy: 0.5709 - loss: 0.9577 - val_accuracy: 0.2862 - val_loss: 0.7720\n",
      "Epoch 2/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6513 - loss: 0.6544 - val_accuracy: 0.6090 - val_loss: 0.6546\n",
      "Epoch 3/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7127 - loss: 0.5502 - val_accuracy: 0.5723 - val_loss: 0.8053\n",
      "Epoch 4/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7636 - loss: 0.4959 - val_accuracy: 0.7432 - val_loss: 0.5717\n",
      "Epoch 5/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7756 - loss: 0.4700 - val_accuracy: 0.6499 - val_loss: 0.7295\n",
      "Epoch 6/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7810 - loss: 0.4877 - val_accuracy: 0.6698 - val_loss: 0.6421\n",
      "Epoch 7/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7962 - loss: 0.4513 - val_accuracy: 0.7285 - val_loss: 0.5142\n",
      "Epoch 8/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7943 - loss: 0.4560 - val_accuracy: 0.7233 - val_loss: 0.5038\n",
      "Epoch 9/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8047 - loss: 0.4406 - val_accuracy: 0.7642 - val_loss: 0.4304\n",
      "Epoch 10/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8156 - loss: 0.4104 - val_accuracy: 0.6866 - val_loss: 0.5153\n",
      "Epoch 11/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8196 - loss: 0.4211 - val_accuracy: 0.6992 - val_loss: 0.5203\n",
      "Epoch 12/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8147 - loss: 0.4277 - val_accuracy: 0.7013 - val_loss: 0.4951\n",
      "Epoch 13/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8240 - loss: 0.3985 - val_accuracy: 0.6237 - val_loss: 0.6055\n",
      "Epoch 14/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8257 - loss: 0.4104 - val_accuracy: 0.6771 - val_loss: 0.5271\n",
      "Epoch 15/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8243 - loss: 0.4040 - val_accuracy: 0.6698 - val_loss: 0.5659\n",
      "Epoch 16/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8237 - loss: 0.4091 - val_accuracy: 0.6824 - val_loss: 0.5457\n",
      "Epoch 17/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8219 - loss: 0.3977 - val_accuracy: 0.6876 - val_loss: 0.5351\n",
      "Epoch 18/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8279 - loss: 0.3867 - val_accuracy: 0.6226 - val_loss: 0.6010\n",
      "Epoch 19/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8309 - loss: 0.3720 - val_accuracy: 0.7180 - val_loss: 0.4427\n",
      "Epoch 20/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8371 - loss: 0.3739 - val_accuracy: 0.6887 - val_loss: 0.4953\n",
      "Epoch 21/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8171 - loss: 0.3946 - val_accuracy: 0.6876 - val_loss: 0.5102\n",
      "Epoch 22/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8399 - loss: 0.3707 - val_accuracy: 0.7191 - val_loss: 0.4661\n",
      "Epoch 23/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.3756 - val_accuracy: 0.7285 - val_loss: 0.4350\n",
      "Epoch 24/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 0.3688 - val_accuracy: 0.6845 - val_loss: 0.5149\n",
      "Epoch 25/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8341 - loss: 0.3728 - val_accuracy: 0.7338 - val_loss: 0.4305\n",
      "Epoch 26/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8384 - loss: 0.3669 - val_accuracy: 0.7149 - val_loss: 0.4408\n",
      "Epoch 27/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 0.3670 - val_accuracy: 0.7044 - val_loss: 0.4694\n",
      "Epoch 28/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8380 - loss: 0.3675 - val_accuracy: 0.6709 - val_loss: 0.5079\n",
      "Epoch 29/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8438 - loss: 0.3534 - val_accuracy: 0.7264 - val_loss: 0.4495\n",
      "Epoch 30/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8312 - loss: 0.3818 - val_accuracy: 0.6897 - val_loss: 0.5246\n",
      "Epoch 31/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8470 - loss: 0.3600 - val_accuracy: 0.7233 - val_loss: 0.4436\n",
      "Epoch 32/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.3394 - val_accuracy: 0.7107 - val_loss: 0.4644\n",
      "Epoch 33/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8487 - loss: 0.3436 - val_accuracy: 0.6908 - val_loss: 0.5014\n",
      "Epoch 34/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8427 - loss: 0.3609 - val_accuracy: 0.6614 - val_loss: 0.5360\n",
      "Epoch 35/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8531 - loss: 0.3471 - val_accuracy: 0.7400 - val_loss: 0.4313\n",
      "Epoch 36/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8493 - loss: 0.3511 - val_accuracy: 0.7516 - val_loss: 0.4246\n",
      "Epoch 37/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8557 - loss: 0.3234 - val_accuracy: 0.7285 - val_loss: 0.4586\n",
      "Epoch 38/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8490 - loss: 0.3419 - val_accuracy: 0.7495 - val_loss: 0.4051\n",
      "Epoch 39/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8485 - loss: 0.3357 - val_accuracy: 0.7243 - val_loss: 0.4626\n",
      "Epoch 40/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8499 - loss: 0.3363 - val_accuracy: 0.7180 - val_loss: 0.4555\n",
      "Epoch 41/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8662 - loss: 0.3244 - val_accuracy: 0.7631 - val_loss: 0.4101\n",
      "Epoch 42/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8686 - loss: 0.3150 - val_accuracy: 0.7537 - val_loss: 0.3786\n",
      "Epoch 43/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8646 - loss: 0.3172 - val_accuracy: 0.7348 - val_loss: 0.4305\n",
      "Epoch 44/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8585 - loss: 0.3141 - val_accuracy: 0.7788 - val_loss: 0.3720\n",
      "Epoch 45/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8590 - loss: 0.3114 - val_accuracy: 0.6971 - val_loss: 0.4811\n",
      "Epoch 46/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.3235 - val_accuracy: 0.6583 - val_loss: 0.5318\n",
      "Epoch 47/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8624 - loss: 0.3225 - val_accuracy: 0.7757 - val_loss: 0.3789\n",
      "Epoch 48/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8528 - loss: 0.3366 - val_accuracy: 0.7610 - val_loss: 0.4338\n",
      "Epoch 49/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8635 - loss: 0.3088 - val_accuracy: 0.7495 - val_loss: 0.4292\n",
      "Epoch 50/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8523 - loss: 0.3238 - val_accuracy: 0.7767 - val_loss: 0.3854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Model Accuracy: 0.8559602649006622\n",
      "ROC-AUC: 0.820052310374891\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "binary_classification_datasets = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"\\n{'='*50}\\nTraining on dataset: {dataset['name']}\\n{'='*50}\")\n",
    "    X_train, X_test, y_train, y_test = preprocess_dataset(dataset)\n",
    "    \n",
    "    # Handle class imbalance\n",
    "    X_train_resampled, y_train_resampled, class_weights = handle_class_imbalance(X_train, y_train)\n",
    "    \n",
    "    # Determine the number of classes\n",
    "    num_classes = len(np.unique(y_train_resampled))\n",
    "    \n",
    "    # Build and train the neural network\n",
    "    input_shape = X_train_resampled.shape[1]\n",
    "    nn_model = build_neural_network(input_shape, num_classes)\n",
    "    \n",
    "    # Convert y_train and y_test to one-hot encoding for multiclass classification\n",
    "    if num_classes > 1:\n",
    "        y_train_resampled = pd.get_dummies(y_train_resampled).values\n",
    "        y_test = pd.get_dummies(y_test).values\n",
    "    else:\n",
    "        binary_classification_datasets.append(dataset[\"name\"])  # Track binary datasets\n",
    "    \n",
    "    # Train the model with class weights\n",
    "    history = nn_model.fit(\n",
    "        X_train_resampled, y_train_resampled, \n",
    "        epochs=50, \n",
    "        batch_size=32, \n",
    "        validation_split=0.2, \n",
    "        verbose=1, \n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    \n",
    "    # Evaluate the neural network\n",
    "    y_pred_nn = nn_model.predict(X_test)\n",
    "    \n",
    "    if num_classes > 1:\n",
    "        # Multiclass classification\n",
    "        y_pred_labels = np.argmax(y_pred_nn, axis=1)  # Predicted class labels\n",
    "        y_test_labels = np.argmax(y_test, axis=1)  # True class labels\n",
    "    else:\n",
    "        # Binary classification\n",
    "        y_pred_labels = (y_pred_nn > 0.5).astype(int)  # Predicted class labels\n",
    "        y_test_labels = y_test  # True class labels\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    nn_acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    \n",
    "    # Calculate ROC-AUC\n",
    "    if num_classes > 1:\n",
    "        # Multiclass ROC-AUC\n",
    "        nn_roc_auc = roc_auc_score(y_test, y_pred_nn, multi_class='ovr', average='weighted')\n",
    "    else:\n",
    "        # Binary ROC-AUC\n",
    "        nn_roc_auc = roc_auc_score(y_test_labels, y_pred_nn)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"dataset\": dataset[\"name\"],\n",
    "        \"accuracy\": nn_acc,\n",
    "        \"roc_auc\": nn_roc_auc\n",
    "    })\n",
    "    \n",
    "    print(f\"Model Accuracy: {nn_acc}\")\n",
    "    print(f\"ROC-AUC: {nn_roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f357bfaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Plot Accuracy for all datasets\n",
    "dataset_names = [result[\"dataset\"] for result in results]\n",
    "accuracies = [result[\"accuracy\"] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(dataset_names, accuracies, color='blue')\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy across Datasets\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6af65a9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd86ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c824d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
