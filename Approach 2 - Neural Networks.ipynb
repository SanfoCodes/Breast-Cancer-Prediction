{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30427054",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, classification_report, precision_recall_curve, auc\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.utils import class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7685490b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset details\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"wisconsin data\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\wisconsin data.csv\",\n",
    "        \"features_numerical\": [\n",
    "            \"radius_mean\", \"texture_mean\", \"perimeter_mean\", \"area_mean\", \"smoothness_mean\", \n",
    "            \"compactness_mean\", \"concavity_mean\", \"concave points_mean\", \"symmetry_mean\", \n",
    "            \"fractal_dimension_mean\", \"radius_se\", \"texture_se\", \"perimeter_se\", \"area_se\", \n",
    "            \"smoothness_se\", \"compactness_se\", \"concavity_se\", \"concave points_se\", \"symmetry_se\", \n",
    "            \"fractal_dimension_se\", \"radius_worst\", \"texture_worst\", \"perimeter_worst\", \n",
    "            \"area_worst\", \"smoothness_worst\", \"compactness_worst\", \"concavity_worst\", \n",
    "            \"concave points_worst\", \"symmetry_worst\", \"fractal_dimension_worst\"\n",
    "        ],\n",
    "        \"features_categorical\": [],\n",
    "        \"target\": \"diagnosis\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"breast-cancer-dataset\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\breast-cancer-dataset.csv\",\n",
    "        \"features_numerical\": [\"Year\", \"Age\", \"Tumor Size (cm)\", \"Inv-Nodes\"],\n",
    "        \"features_categorical\": [\"Menopause\", \"Breast\", \"Metastasis\", \"Breast Quadrant\", \"History\"],\n",
    "        \"target\": \"Diagnosis Result\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"BRCA\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\BRCA.csv\",\n",
    "        \"features_numerical\": [\"Age\", \"Protein1\", \"Protein2\", \"Protein3\", \"Protein4\"],\n",
    "        \"features_categorical\": [\"Gender\", \"Tumour_Stage\", \"Histology\", \"ER status\", \"PR status\", \"HER2 status\", \"Surgery_type\"],\n",
    "        \"target\": \"Patient_Status\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"german bs data\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\german bs data.csv\",\n",
    "        \"features_numerical\": [\"age\", \"size\", \"grade\", \"nodes\", \"pgr\", \"er\", \"rfstime\"],\n",
    "        \"features_categorical\": [\"meno\", \"hormon\"],\n",
    "        \"target\": \"status\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"seer data\",\n",
    "        \"path\": \"C:\\\\Users\\\\arpitha_work\\\\Downloads\\\\TRU MSCDS\\\\Sem2\\\\DS Seminar\\\\Project 1\\\\Datasets\\\\seer data.csv\",\n",
    "        \"features_numerical\": [\"Age\", \"Survival Months\", \"Regional Node Examined\"],\n",
    "        \"features_categorical\": [\n",
    "            \"Race\", \"Marital Status\", \"T Stage \", \"N Stage\", \"6th Stage\", \"differentiate\", \n",
    "            \"Grade\", \"A Stage\", \"Tumor Size\", \"Estrogen Status\", \"Progesterone Status\", \n",
    "            \"Reginol Node Positive\"\n",
    "        ],\n",
    "        \"target\": \"Status\"\n",
    "    }\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21e920c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset):\n",
    "    print(f\"Processing dataset: {dataset['name']}\")\n",
    "    df = pd.read_csv(dataset['path'])\n",
    "    \n",
    "    # Verify that all specified columns exist in the dataset\n",
    "    missing_numerical = [col for col in dataset[\"features_numerical\"] if col not in df.columns]\n",
    "    missing_categorical = [col for col in dataset[\"features_categorical\"] if col not in df.columns]\n",
    "    \n",
    "    if missing_numerical or missing_categorical:\n",
    "        raise ValueError(\n",
    "            f\"Missing columns in dataset {dataset['name']}: \"\n",
    "            f\"Numerical: {missing_numerical}, Categorical: {missing_categorical}\"\n",
    "        )\n",
    "    \n",
    "    # Clean numerical columns: replace non-numeric values with NaN\n",
    "    for col in dataset[\"features_numerical\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')  # Convert to numeric, invalid values become NaN\n",
    "    \n",
    "    # Drop rows with missing values in numerical columns\n",
    "    df.dropna(subset=dataset[\"features_numerical\"], inplace=True)\n",
    "    \n",
    "    # Extract numerical and categorical features\n",
    "    X_num = df[dataset[\"features_numerical\"]]\n",
    "    X_cat = df[dataset[\"features_categorical\"]] if dataset[\"features_categorical\"] else pd.DataFrame()\n",
    "    y = df[dataset[\"target\"]]\n",
    "\n",
    "    # Encode categorical variables if they exist\n",
    "    if not X_cat.empty:\n",
    "        X_cat = pd.get_dummies(X_cat, drop_first=True)\n",
    "    \n",
    "    # Encode target variable if it's categorical\n",
    "    if y.dtype == 'object':\n",
    "        le = LabelEncoder()\n",
    "        y = le.fit_transform(y)\n",
    "\n",
    "    # Combine features\n",
    "    X = pd.concat([X_num, X_cat], axis=1) if not X_cat.empty else X_num\n",
    "\n",
    "    # Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "    # Scale numerical features (keeping them as DataFrames)\n",
    "    scaler = StandardScaler()\n",
    "    X_train[dataset[\"features_numerical\"]] = scaler.fit_transform(X_train[dataset[\"features_numerical\"]])\n",
    "    X_test[dataset[\"features_numerical\"]] = scaler.transform(X_test[dataset[\"features_numerical\"]])\n",
    "\n",
    "    # Convert all data to float32 for TensorFlow compatibility\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    y_train = y_train.astype(np.float32)\n",
    "    y_test = y_test.astype(np.float32)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49efe02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_neural_network(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(num_classes, activation='softmax' if num_classes > 1 else 'sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), \n",
    "                  loss='categorical_crossentropy' if num_classes > 1 else 'binary_crossentropy', \n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23bdb21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_class_imbalance(X_train, y_train):\n",
    "    # Apply SMOTE for oversampling\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Calculate class weights\n",
    "    class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train_resampled), y=y_train_resampled)\n",
    "    class_weights = dict(enumerate(class_weights))\n",
    "    \n",
    "    return X_train_resampled, y_train_resampled, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95e14da7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training on dataset: wisconsin data\n",
      "==================================================\n",
      "Processing dataset: wisconsin data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 56ms/step - accuracy: 0.6616 - loss: 0.6141 - val_accuracy: 0.9100 - val_loss: 0.4205\n",
      "Epoch 2/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9281 - loss: 0.2794 - val_accuracy: 0.9300 - val_loss: 0.2347\n",
      "Epoch 3/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9383 - loss: 0.1783 - val_accuracy: 0.9700 - val_loss: 0.1268\n",
      "Epoch 4/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9718 - loss: 0.1054 - val_accuracy: 0.9700 - val_loss: 0.0871\n",
      "Epoch 5/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9733 - loss: 0.0939 - val_accuracy: 0.9800 - val_loss: 0.0612\n",
      "Epoch 6/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9790 - loss: 0.0831 - val_accuracy: 0.9800 - val_loss: 0.0490\n",
      "Epoch 7/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9706 - loss: 0.0902 - val_accuracy: 0.9800 - val_loss: 0.0461\n",
      "Epoch 8/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9758 - loss: 0.0765 - val_accuracy: 0.9800 - val_loss: 0.0273\n",
      "Epoch 9/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9800 - loss: 0.0571 - val_accuracy: 0.9800 - val_loss: 0.0252\n",
      "Epoch 10/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9807 - loss: 0.0584 - val_accuracy: 0.9900 - val_loss: 0.0190\n",
      "Epoch 11/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9859 - loss: 0.0479 - val_accuracy: 0.9900 - val_loss: 0.0189\n",
      "Epoch 12/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9852 - loss: 0.0474 - val_accuracy: 0.9900 - val_loss: 0.0164\n",
      "Epoch 13/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9855 - loss: 0.0545 - val_accuracy: 0.9900 - val_loss: 0.0161\n",
      "Epoch 14/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9799 - loss: 0.0540 - val_accuracy: 0.9900 - val_loss: 0.0121\n",
      "Epoch 15/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9746 - loss: 0.0434 - val_accuracy: 0.9900 - val_loss: 0.0106\n",
      "Epoch 16/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0295 - val_accuracy: 0.9900 - val_loss: 0.0097\n",
      "Epoch 17/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9791 - loss: 0.0432 - val_accuracy: 1.0000 - val_loss: 0.0068\n",
      "Epoch 18/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9840 - loss: 0.0369 - val_accuracy: 0.9900 - val_loss: 0.0072\n",
      "Epoch 19/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9885 - loss: 0.0433 - val_accuracy: 0.9900 - val_loss: 0.0087\n",
      "Epoch 20/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9843 - loss: 0.0347 - val_accuracy: 1.0000 - val_loss: 0.0061\n",
      "Epoch 21/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0311 - val_accuracy: 0.9900 - val_loss: 0.0079\n",
      "Epoch 22/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9947 - loss: 0.0286 - val_accuracy: 1.0000 - val_loss: 0.0062\n",
      "Epoch 23/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9920 - loss: 0.0252 - val_accuracy: 1.0000 - val_loss: 0.0043\n",
      "Epoch 24/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9901 - loss: 0.0264 - val_accuracy: 1.0000 - val_loss: 0.0048\n",
      "Epoch 25/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9905 - loss: 0.0168 - val_accuracy: 1.0000 - val_loss: 0.0041\n",
      "Epoch 26/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9953 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 0.0038\n",
      "Epoch 27/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9975 - loss: 0.0127 - val_accuracy: 1.0000 - val_loss: 0.0035\n",
      "Epoch 28/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9985 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0039\n",
      "Epoch 29/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9905 - loss: 0.0255 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9875 - loss: 0.0202 - val_accuracy: 1.0000 - val_loss: 0.0024\n",
      "Epoch 31/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9892 - loss: 0.0517 - val_accuracy: 1.0000 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9839 - loss: 0.0340 - val_accuracy: 1.0000 - val_loss: 0.0014\n",
      "Epoch 33/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9988 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 34/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9961 - loss: 0.0139 - val_accuracy: 1.0000 - val_loss: 0.0019\n",
      "Epoch 35/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9883 - loss: 0.0190 - val_accuracy: 1.0000 - val_loss: 0.0011\n",
      "Epoch 36/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9928 - loss: 0.0158 - val_accuracy: 1.0000 - val_loss: 0.0017\n",
      "Epoch 37/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9952 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 0.0013\n",
      "Epoch 38/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 9.0443e-04\n",
      "Epoch 39/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9929 - loss: 0.0123 - val_accuracy: 1.0000 - val_loss: 6.3395e-04\n",
      "Epoch 40/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9933 - loss: 0.0177 - val_accuracy: 1.0000 - val_loss: 9.9116e-04\n",
      "Epoch 41/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9942 - loss: 0.0113 - val_accuracy: 1.0000 - val_loss: 8.3403e-04\n",
      "Epoch 42/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9854 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 3.9874e-04\n",
      "Epoch 43/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9826 - loss: 0.0404 - val_accuracy: 1.0000 - val_loss: 0.0012\n",
      "Epoch 44/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9964 - loss: 0.0072 - val_accuracy: 1.0000 - val_loss: 8.6425e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9910 - loss: 0.0109 - val_accuracy: 1.0000 - val_loss: 5.0992e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9990 - loss: 0.0111 - val_accuracy: 1.0000 - val_loss: 5.9214e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9995 - loss: 0.0084 - val_accuracy: 1.0000 - val_loss: 8.6697e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9968 - loss: 0.0155 - val_accuracy: 1.0000 - val_loss: 7.8991e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9949 - loss: 0.0096 - val_accuracy: 1.0000 - val_loss: 2.8708e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9993 - loss: 0.0034 - val_accuracy: 1.0000 - val_loss: 2.9341e-04\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n",
      "Model Accuracy: 0.9824561403508771\n",
      "ROC-AUC: 0.9935201125867629\n",
      "\n",
      "==================================================\n",
      "Training on dataset: breast-cancer-dataset\n",
      "==================================================\n",
      "Processing dataset: breast-cancer-dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 160ms/step - accuracy: 0.6336 - loss: 0.6584 - val_accuracy: 0.7941 - val_loss: 0.6398\n",
      "Epoch 2/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7924 - loss: 0.5546 - val_accuracy: 0.8235 - val_loss: 0.6150\n",
      "Epoch 3/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8702 - loss: 0.4503 - val_accuracy: 0.8235 - val_loss: 0.6203\n",
      "Epoch 4/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8650 - loss: 0.4117 - val_accuracy: 0.8235 - val_loss: 0.6574\n",
      "Epoch 5/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9001 - loss: 0.3405 - val_accuracy: 0.8235 - val_loss: 0.6935\n",
      "Epoch 6/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8962 - loss: 0.3014 - val_accuracy: 0.8235 - val_loss: 0.6980\n",
      "Epoch 7/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9046 - loss: 0.2840 - val_accuracy: 0.8235 - val_loss: 0.6217\n",
      "Epoch 8/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9004 - loss: 0.2495 - val_accuracy: 0.8235 - val_loss: 0.5435\n",
      "Epoch 9/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8937 - loss: 0.2417 - val_accuracy: 0.8235 - val_loss: 0.4898\n",
      "Epoch 10/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9455 - loss: 0.2221 - val_accuracy: 0.8235 - val_loss: 0.4580\n",
      "Epoch 11/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9098 - loss: 0.2881 - val_accuracy: 0.8235 - val_loss: 0.4335\n",
      "Epoch 12/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9215 - loss: 0.2062 - val_accuracy: 0.8235 - val_loss: 0.4573\n",
      "Epoch 13/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9170 - loss: 0.2249 - val_accuracy: 0.8235 - val_loss: 0.4685\n",
      "Epoch 14/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8975 - loss: 0.2319 - val_accuracy: 0.8235 - val_loss: 0.4363\n",
      "Epoch 15/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9054 - loss: 0.2307 - val_accuracy: 0.8235 - val_loss: 0.3883\n",
      "Epoch 16/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9152 - loss: 0.2234 - val_accuracy: 0.8235 - val_loss: 0.3449\n",
      "Epoch 17/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9277 - loss: 0.1704 - val_accuracy: 0.8529 - val_loss: 0.3241\n",
      "Epoch 18/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9144 - loss: 0.2100 - val_accuracy: 0.8824 - val_loss: 0.3074\n",
      "Epoch 19/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9240 - loss: 0.2094 - val_accuracy: 0.8824 - val_loss: 0.2986\n",
      "Epoch 20/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9065 - loss: 0.2160 - val_accuracy: 0.8824 - val_loss: 0.3005\n",
      "Epoch 21/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9045 - loss: 0.1861 - val_accuracy: 0.8824 - val_loss: 0.2977\n",
      "Epoch 22/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9313 - loss: 0.1641 - val_accuracy: 0.8824 - val_loss: 0.2875\n",
      "Epoch 23/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9156 - loss: 0.1789 - val_accuracy: 0.9118 - val_loss: 0.2631\n",
      "Epoch 24/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9407 - loss: 0.1400 - val_accuracy: 0.9118 - val_loss: 0.2630\n",
      "Epoch 25/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9504 - loss: 0.1740 - val_accuracy: 0.9118 - val_loss: 0.2732\n",
      "Epoch 26/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9440 - loss: 0.1571 - val_accuracy: 0.8529 - val_loss: 0.2988\n",
      "Epoch 27/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9326 - loss: 0.2031 - val_accuracy: 0.8529 - val_loss: 0.2959\n",
      "Epoch 28/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9515 - loss: 0.1601 - val_accuracy: 0.8824 - val_loss: 0.2849\n",
      "Epoch 29/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9114 - loss: 0.1983 - val_accuracy: 0.8824 - val_loss: 0.2585\n",
      "Epoch 30/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9492 - loss: 0.1442 - val_accuracy: 0.8824 - val_loss: 0.2176\n",
      "Epoch 31/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9586 - loss: 0.1720 - val_accuracy: 0.8824 - val_loss: 0.2091\n",
      "Epoch 32/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9558 - loss: 0.1435 - val_accuracy: 0.8824 - val_loss: 0.2213\n",
      "Epoch 33/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9333 - loss: 0.1808 - val_accuracy: 0.8824 - val_loss: 0.2422\n",
      "Epoch 34/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9342 - loss: 0.1846 - val_accuracy: 0.9118 - val_loss: 0.2673\n",
      "Epoch 35/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9234 - loss: 0.1696 - val_accuracy: 0.9118 - val_loss: 0.2561\n",
      "Epoch 36/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9306 - loss: 0.1480 - val_accuracy: 0.9118 - val_loss: 0.2456\n",
      "Epoch 37/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9306 - loss: 0.1607 - val_accuracy: 0.9118 - val_loss: 0.2459\n",
      "Epoch 38/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9504 - loss: 0.1320 - val_accuracy: 0.9118 - val_loss: 0.2544\n",
      "Epoch 39/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9380 - loss: 0.1745 - val_accuracy: 0.9118 - val_loss: 0.2596\n",
      "Epoch 40/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9559 - loss: 0.1611 - val_accuracy: 0.9118 - val_loss: 0.2448\n",
      "Epoch 41/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9434 - loss: 0.1324 - val_accuracy: 0.9118 - val_loss: 0.2401\n",
      "Epoch 42/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9619 - loss: 0.1105 - val_accuracy: 0.9118 - val_loss: 0.2545\n",
      "Epoch 43/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9620 - loss: 0.1230 - val_accuracy: 0.9118 - val_loss: 0.2733\n",
      "Epoch 44/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9376 - loss: 0.1667 - val_accuracy: 0.9118 - val_loss: 0.2844\n",
      "Epoch 45/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9695 - loss: 0.1122 - val_accuracy: 0.9118 - val_loss: 0.3009\n",
      "Epoch 46/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9414 - loss: 0.1250 - val_accuracy: 0.9118 - val_loss: 0.3093\n",
      "Epoch 47/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9675 - loss: 0.1164 - val_accuracy: 0.9118 - val_loss: 0.2935\n",
      "Epoch 48/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9641 - loss: 0.1031 - val_accuracy: 0.9118 - val_loss: 0.2864\n",
      "Epoch 49/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9657 - loss: 0.1132 - val_accuracy: 0.9118 - val_loss: 0.2614\n",
      "Epoch 50/50\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9564 - loss: 0.1353 - val_accuracy: 0.9118 - val_loss: 0.2569\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step  \n",
      "Model Accuracy: 0.90625\n",
      "ROC-AUC: 0.9563492063492063\n",
      "\n",
      "==================================================\n",
      "Training on dataset: BRCA\n",
      "==================================================\n",
      "Processing dataset: BRCA\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 50ms/step - accuracy: 0.3791 - loss: 1.0882 - val_accuracy: 0.0000e+00 - val_loss: 1.5514\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.4714 - loss: 1.0283 - val_accuracy: 0.0000e+00 - val_loss: 1.7573\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4863 - loss: 1.0099 - val_accuracy: 0.0000e+00 - val_loss: 1.6423\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.4996 - loss: 0.9949 - val_accuracy: 0.0000e+00 - val_loss: 1.5497\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.5609 - loss: 0.9297 - val_accuracy: 0.0000e+00 - val_loss: 1.5828\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5512 - loss: 0.9186 - val_accuracy: 0.0000e+00 - val_loss: 1.5071\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5595 - loss: 0.9042 - val_accuracy: 0.0000e+00 - val_loss: 1.4815\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5204 - loss: 0.9018 - val_accuracy: 0.0000e+00 - val_loss: 1.3968\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5948 - loss: 0.8655 - val_accuracy: 0.1308 - val_loss: 1.3177\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5780 - loss: 0.8554 - val_accuracy: 0.2991 - val_loss: 1.2491\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6373 - loss: 0.7898 - val_accuracy: 0.3084 - val_loss: 1.2226\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6493 - loss: 0.7559 - val_accuracy: 0.3738 - val_loss: 1.1213\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6611 - loss: 0.7501 - val_accuracy: 0.5607 - val_loss: 0.9941\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6732 - loss: 0.7206 - val_accuracy: 0.5981 - val_loss: 0.9458\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6829 - loss: 0.7159 - val_accuracy: 0.6636 - val_loss: 0.8280\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7198 - loss: 0.6540 - val_accuracy: 0.7009 - val_loss: 0.7813\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7217 - loss: 0.6551 - val_accuracy: 0.8131 - val_loss: 0.6246\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7304 - loss: 0.6243 - val_accuracy: 0.7196 - val_loss: 0.6707\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8016 - loss: 0.5610 - val_accuracy: 0.8318 - val_loss: 0.5711\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7839 - loss: 0.5701 - val_accuracy: 0.8505 - val_loss: 0.5171\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7084 - loss: 0.6164 - val_accuracy: 0.8879 - val_loss: 0.4852\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7831 - loss: 0.5796 - val_accuracy: 0.9626 - val_loss: 0.4264\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7514 - loss: 0.5421 - val_accuracy: 0.9720 - val_loss: 0.3503\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8172 - loss: 0.5077 - val_accuracy: 0.9720 - val_loss: 0.3466\n",
      "Epoch 25/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8226 - loss: 0.4739 - val_accuracy: 0.9907 - val_loss: 0.2593\n",
      "Epoch 26/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7651 - loss: 0.4918 - val_accuracy: 0.9720 - val_loss: 0.2732\n",
      "Epoch 27/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8112 - loss: 0.4914 - val_accuracy: 0.9907 - val_loss: 0.2549\n",
      "Epoch 28/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8344 - loss: 0.4190 - val_accuracy: 0.9813 - val_loss: 0.2508\n",
      "Epoch 29/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8324 - loss: 0.4495 - val_accuracy: 1.0000 - val_loss: 0.1882\n",
      "Epoch 30/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7622 - loss: 0.5009 - val_accuracy: 0.9907 - val_loss: 0.1893\n",
      "Epoch 31/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8009 - loss: 0.4675 - val_accuracy: 0.9813 - val_loss: 0.1975\n",
      "Epoch 32/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8608 - loss: 0.3934 - val_accuracy: 0.9720 - val_loss: 0.2018\n",
      "Epoch 33/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8474 - loss: 0.4020 - val_accuracy: 0.9907 - val_loss: 0.1690\n",
      "Epoch 34/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8218 - loss: 0.4122 - val_accuracy: 1.0000 - val_loss: 0.1328\n",
      "Epoch 35/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8368 - loss: 0.4150 - val_accuracy: 1.0000 - val_loss: 0.1453\n",
      "Epoch 36/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8943 - loss: 0.3259 - val_accuracy: 1.0000 - val_loss: 0.1204\n",
      "Epoch 37/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8304 - loss: 0.4212 - val_accuracy: 1.0000 - val_loss: 0.1164\n",
      "Epoch 38/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8784 - loss: 0.3433 - val_accuracy: 1.0000 - val_loss: 0.1099\n",
      "Epoch 39/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8681 - loss: 0.3651 - val_accuracy: 1.0000 - val_loss: 0.0968\n",
      "Epoch 40/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8867 - loss: 0.3240 - val_accuracy: 1.0000 - val_loss: 0.0968\n",
      "Epoch 41/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8630 - loss: 0.3727 - val_accuracy: 1.0000 - val_loss: 0.1054\n",
      "Epoch 42/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8741 - loss: 0.3569 - val_accuracy: 1.0000 - val_loss: 0.0967\n",
      "Epoch 43/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8563 - loss: 0.3544 - val_accuracy: 1.0000 - val_loss: 0.0681\n",
      "Epoch 44/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8708 - loss: 0.3268 - val_accuracy: 1.0000 - val_loss: 0.0770\n",
      "Epoch 45/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8917 - loss: 0.3004 - val_accuracy: 1.0000 - val_loss: 0.1039\n",
      "Epoch 46/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8707 - loss: 0.3221 - val_accuracy: 1.0000 - val_loss: 0.0669\n",
      "Epoch 47/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8809 - loss: 0.2969 - val_accuracy: 1.0000 - val_loss: 0.0637\n",
      "Epoch 48/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8866 - loss: 0.2808 - val_accuracy: 1.0000 - val_loss: 0.0722\n",
      "Epoch 49/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8780 - loss: 0.2980 - val_accuracy: 1.0000 - val_loss: 0.0688\n",
      "Epoch 50/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9219 - loss: 0.2435 - val_accuracy: 0.9813 - val_loss: 0.0900\n",
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 160ms/stepWARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BBFA5EC860> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "Model Accuracy: 0.6237623762376238\n",
      "ROC-AUC: 0.5305088355341835\n",
      "\n",
      "==================================================\n",
      "Training on dataset: german bs data\n",
      "==================================================\n",
      "Processing dataset: german bs data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5103 - loss: 0.6898 - val_accuracy: 0.4220 - val_loss: 0.7254\n",
      "Epoch 2/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6477 - loss: 0.6227 - val_accuracy: 0.6330 - val_loss: 0.6556\n",
      "Epoch 3/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7367 - loss: 0.5595 - val_accuracy: 0.7064 - val_loss: 0.6187\n",
      "Epoch 4/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6945 - loss: 0.5525 - val_accuracy: 0.7248 - val_loss: 0.6079\n",
      "Epoch 5/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7280 - loss: 0.5588 - val_accuracy: 0.7339 - val_loss: 0.6035\n",
      "Epoch 6/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7642 - loss: 0.4975 - val_accuracy: 0.7248 - val_loss: 0.5647\n",
      "Epoch 7/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7421 - loss: 0.5500 - val_accuracy: 0.7064 - val_loss: 0.5458\n",
      "Epoch 8/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7189 - loss: 0.5569 - val_accuracy: 0.7339 - val_loss: 0.5955\n",
      "Epoch 9/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7338 - loss: 0.5276 - val_accuracy: 0.7248 - val_loss: 0.5735\n",
      "Epoch 10/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6969 - loss: 0.5558 - val_accuracy: 0.7339 - val_loss: 0.5570\n",
      "Epoch 11/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7580 - loss: 0.5231 - val_accuracy: 0.7248 - val_loss: 0.5634\n",
      "Epoch 12/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7548 - loss: 0.5206 - val_accuracy: 0.7156 - val_loss: 0.5647\n",
      "Epoch 13/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7130 - loss: 0.5430 - val_accuracy: 0.7156 - val_loss: 0.5680\n",
      "Epoch 14/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7313 - loss: 0.5257 - val_accuracy: 0.7248 - val_loss: 0.5475\n",
      "Epoch 15/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6994 - loss: 0.5611 - val_accuracy: 0.7248 - val_loss: 0.5514\n",
      "Epoch 16/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7218 - loss: 0.5379 - val_accuracy: 0.7248 - val_loss: 0.5610\n",
      "Epoch 17/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7207 - loss: 0.5315 - val_accuracy: 0.7064 - val_loss: 0.5602\n",
      "Epoch 18/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7207 - loss: 0.5462 - val_accuracy: 0.7248 - val_loss: 0.5405\n",
      "Epoch 19/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7419 - loss: 0.5307 - val_accuracy: 0.7248 - val_loss: 0.5500\n",
      "Epoch 20/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7518 - loss: 0.5316 - val_accuracy: 0.7156 - val_loss: 0.5540\n",
      "Epoch 21/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7295 - loss: 0.5322 - val_accuracy: 0.7248 - val_loss: 0.5478\n",
      "Epoch 22/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7222 - loss: 0.5197 - val_accuracy: 0.7248 - val_loss: 0.5415\n",
      "Epoch 23/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7547 - loss: 0.4960 - val_accuracy: 0.7156 - val_loss: 0.5510\n",
      "Epoch 24/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7625 - loss: 0.4844 - val_accuracy: 0.7156 - val_loss: 0.5141\n",
      "Epoch 25/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7496 - loss: 0.5027 - val_accuracy: 0.7156 - val_loss: 0.5213\n",
      "Epoch 26/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7551 - loss: 0.5186 - val_accuracy: 0.7156 - val_loss: 0.5227\n",
      "Epoch 27/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7504 - loss: 0.5111 - val_accuracy: 0.7339 - val_loss: 0.5167\n",
      "Epoch 28/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7431 - loss: 0.4923 - val_accuracy: 0.7248 - val_loss: 0.5293\n",
      "Epoch 29/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7546 - loss: 0.5030 - val_accuracy: 0.7248 - val_loss: 0.5054\n",
      "Epoch 30/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7401 - loss: 0.4866 - val_accuracy: 0.7248 - val_loss: 0.5177\n",
      "Epoch 31/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7948 - loss: 0.4654 - val_accuracy: 0.7248 - val_loss: 0.5074\n",
      "Epoch 32/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7794 - loss: 0.4823 - val_accuracy: 0.7248 - val_loss: 0.5145\n",
      "Epoch 33/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7533 - loss: 0.4953 - val_accuracy: 0.7248 - val_loss: 0.5182\n",
      "Epoch 34/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7660 - loss: 0.4739 - val_accuracy: 0.7248 - val_loss: 0.5297\n",
      "Epoch 35/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7797 - loss: 0.4467 - val_accuracy: 0.7064 - val_loss: 0.5378\n",
      "Epoch 36/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7674 - loss: 0.4712 - val_accuracy: 0.7248 - val_loss: 0.5210\n",
      "Epoch 37/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7763 - loss: 0.4553 - val_accuracy: 0.7523 - val_loss: 0.5008\n",
      "Epoch 38/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7568 - loss: 0.4949 - val_accuracy: 0.7339 - val_loss: 0.4993\n",
      "Epoch 39/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7947 - loss: 0.4533 - val_accuracy: 0.7431 - val_loss: 0.5243\n",
      "Epoch 40/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7766 - loss: 0.4423 - val_accuracy: 0.7248 - val_loss: 0.5117\n",
      "Epoch 41/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7429 - loss: 0.4934 - val_accuracy: 0.7339 - val_loss: 0.5130\n",
      "Epoch 42/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8100 - loss: 0.4536 - val_accuracy: 0.7339 - val_loss: 0.5147\n",
      "Epoch 43/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7306 - loss: 0.5107 - val_accuracy: 0.7431 - val_loss: 0.5237\n",
      "Epoch 44/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7590 - loss: 0.4591 - val_accuracy: 0.7248 - val_loss: 0.5047\n",
      "Epoch 45/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7486 - loss: 0.4654 - val_accuracy: 0.7339 - val_loss: 0.5347\n",
      "Epoch 46/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7794 - loss: 0.4516 - val_accuracy: 0.7156 - val_loss: 0.5177\n",
      "Epoch 47/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7656 - loss: 0.4547 - val_accuracy: 0.7248 - val_loss: 0.5031\n",
      "Epoch 48/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7675 - loss: 0.4389 - val_accuracy: 0.7248 - val_loss: 0.5172\n",
      "Epoch 49/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7749 - loss: 0.4686 - val_accuracy: 0.7339 - val_loss: 0.5013\n",
      "Epoch 50/50\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7599 - loss: 0.4644 - val_accuracy: 0.7431 - val_loss: 0.4776\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001BBFA82A480> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
      "Model Accuracy: 0.6747572815533981\n",
      "ROC-AUC: 0.7406130268199234\n",
      "\n",
      "==================================================\n",
      "Training on dataset: seer data\n",
      "==================================================\n",
      "Processing dataset: seer data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arpitha_work\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:85: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.5497 - loss: 0.9752 - val_accuracy: 0.3124 - val_loss: 0.7478\n",
      "Epoch 2/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6548 - loss: 0.6582 - val_accuracy: 0.6646 - val_loss: 0.6376\n",
      "Epoch 3/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7287 - loss: 0.5697 - val_accuracy: 0.7505 - val_loss: 0.5466\n",
      "Epoch 4/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7524 - loss: 0.5151 - val_accuracy: 0.7201 - val_loss: 0.6132\n",
      "Epoch 5/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7786 - loss: 0.4785 - val_accuracy: 0.7034 - val_loss: 0.6067\n",
      "Epoch 6/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7874 - loss: 0.4606 - val_accuracy: 0.7002 - val_loss: 0.6408\n",
      "Epoch 7/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8022 - loss: 0.4448 - val_accuracy: 0.7757 - val_loss: 0.4662\n",
      "Epoch 8/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7966 - loss: 0.4432 - val_accuracy: 0.6426 - val_loss: 0.6476\n",
      "Epoch 9/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8100 - loss: 0.4300 - val_accuracy: 0.7034 - val_loss: 0.5239\n",
      "Epoch 10/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8192 - loss: 0.4132 - val_accuracy: 0.6373 - val_loss: 0.5888\n",
      "Epoch 11/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8037 - loss: 0.4339 - val_accuracy: 0.6310 - val_loss: 0.6091\n",
      "Epoch 12/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8054 - loss: 0.4140 - val_accuracy: 0.6457 - val_loss: 0.5580\n",
      "Epoch 13/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8175 - loss: 0.4138 - val_accuracy: 0.6698 - val_loss: 0.5305\n",
      "Epoch 14/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8246 - loss: 0.3967 - val_accuracy: 0.5922 - val_loss: 0.6098\n",
      "Epoch 15/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8313 - loss: 0.3892 - val_accuracy: 0.6646 - val_loss: 0.5638\n",
      "Epoch 16/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8296 - loss: 0.3863 - val_accuracy: 0.6080 - val_loss: 0.6165\n",
      "Epoch 17/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8195 - loss: 0.4085 - val_accuracy: 0.6782 - val_loss: 0.5345\n",
      "Epoch 18/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8297 - loss: 0.3809 - val_accuracy: 0.6352 - val_loss: 0.5879\n",
      "Epoch 19/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8334 - loss: 0.3784 - val_accuracy: 0.7191 - val_loss: 0.4747\n",
      "Epoch 20/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.3819 - val_accuracy: 0.6635 - val_loss: 0.5695\n",
      "Epoch 21/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8241 - loss: 0.3883 - val_accuracy: 0.7159 - val_loss: 0.4703\n",
      "Epoch 22/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8392 - loss: 0.3710 - val_accuracy: 0.6572 - val_loss: 0.5446\n",
      "Epoch 23/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8256 - loss: 0.3782 - val_accuracy: 0.6813 - val_loss: 0.5251\n",
      "Epoch 24/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8393 - loss: 0.3749 - val_accuracy: 0.6289 - val_loss: 0.6083\n",
      "Epoch 25/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8347 - loss: 0.3818 - val_accuracy: 0.7023 - val_loss: 0.4666\n",
      "Epoch 26/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8365 - loss: 0.3820 - val_accuracy: 0.6939 - val_loss: 0.4919\n",
      "Epoch 27/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8345 - loss: 0.3771 - val_accuracy: 0.6908 - val_loss: 0.4643\n",
      "Epoch 28/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8318 - loss: 0.3668 - val_accuracy: 0.7327 - val_loss: 0.4074\n",
      "Epoch 29/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8397 - loss: 0.3666 - val_accuracy: 0.6667 - val_loss: 0.5483\n",
      "Epoch 30/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8389 - loss: 0.3549 - val_accuracy: 0.6876 - val_loss: 0.4952\n",
      "Epoch 31/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8336 - loss: 0.3747 - val_accuracy: 0.7421 - val_loss: 0.4302\n",
      "Epoch 32/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8349 - loss: 0.3490 - val_accuracy: 0.6866 - val_loss: 0.5085\n",
      "Epoch 33/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8374 - loss: 0.3575 - val_accuracy: 0.6740 - val_loss: 0.5660\n",
      "Epoch 34/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8443 - loss: 0.3548 - val_accuracy: 0.7055 - val_loss: 0.4835\n",
      "Epoch 35/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8416 - loss: 0.3462 - val_accuracy: 0.7128 - val_loss: 0.4722\n",
      "Epoch 36/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8437 - loss: 0.3471 - val_accuracy: 0.7086 - val_loss: 0.4475\n",
      "Epoch 37/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8508 - loss: 0.3452 - val_accuracy: 0.7243 - val_loss: 0.4511\n",
      "Epoch 38/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8449 - loss: 0.3489 - val_accuracy: 0.7075 - val_loss: 0.4657\n",
      "Epoch 39/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8355 - loss: 0.3485 - val_accuracy: 0.7180 - val_loss: 0.4573\n",
      "Epoch 40/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8443 - loss: 0.3520 - val_accuracy: 0.6908 - val_loss: 0.5068\n",
      "Epoch 41/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8510 - loss: 0.3395 - val_accuracy: 0.7243 - val_loss: 0.4529\n",
      "Epoch 42/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8554 - loss: 0.3192 - val_accuracy: 0.7379 - val_loss: 0.4245\n",
      "Epoch 43/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8513 - loss: 0.3323 - val_accuracy: 0.7159 - val_loss: 0.4511\n",
      "Epoch 44/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8520 - loss: 0.3281 - val_accuracy: 0.7275 - val_loss: 0.4306\n",
      "Epoch 45/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8570 - loss: 0.3295 - val_accuracy: 0.7013 - val_loss: 0.4559\n",
      "Epoch 46/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8504 - loss: 0.3311 - val_accuracy: 0.7400 - val_loss: 0.4522\n",
      "Epoch 47/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8538 - loss: 0.3360 - val_accuracy: 0.7348 - val_loss: 0.4650\n",
      "Epoch 48/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8516 - loss: 0.3379 - val_accuracy: 0.7306 - val_loss: 0.4464\n",
      "Epoch 49/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8562 - loss: 0.3237 - val_accuracy: 0.7400 - val_loss: 0.4449\n",
      "Epoch 50/50\n",
      "\u001b[1m120/120\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8736 - loss: 0.3072 - val_accuracy: 0.7694 - val_loss: 0.3779\n",
      "\u001b[1m38/38\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
      "Model Accuracy: 0.8584437086092715\n",
      "ROC-AUC: 0.818556973395683\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "binary_classification_datasets = []\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"\\n{'='*50}\\nTraining on dataset: {dataset['name']}\\n{'='*50}\")\n",
    "    X_train, X_test, y_train, y_test = preprocess_dataset(dataset)\n",
    "    \n",
    "    # Handle class imbalance\n",
    "    X_train_resampled, y_train_resampled, class_weights = handle_class_imbalance(X_train, y_train)\n",
    "    \n",
    "    # Determine the number of classes\n",
    "    num_classes = len(np.unique(y_train_resampled))\n",
    "    \n",
    "    # Build and train the neural network\n",
    "    input_shape = X_train_resampled.shape[1]\n",
    "    nn_model = build_neural_network(input_shape, num_classes)\n",
    "    \n",
    "    # Convert y_train and y_test to one-hot encoding for multiclass classification\n",
    "    if num_classes > 1:\n",
    "        y_train_resampled = pd.get_dummies(y_train_resampled).values\n",
    "        y_test = pd.get_dummies(y_test).values\n",
    "    else:\n",
    "        binary_classification_datasets.append(dataset[\"name\"])  # Track binary datasets\n",
    "    \n",
    "    # Train the model with class weights\n",
    "    history = nn_model.fit(\n",
    "        X_train_resampled, y_train_resampled, \n",
    "        epochs=50, \n",
    "        batch_size=32, \n",
    "        validation_split=0.2, \n",
    "        verbose=1, \n",
    "        class_weight=class_weights\n",
    "    )\n",
    "    \n",
    "    # Evaluate the neural network\n",
    "    y_pred_nn = nn_model.predict(X_test)\n",
    "    \n",
    "    if num_classes > 1:\n",
    "        # Multiclass classification\n",
    "        y_pred_labels = np.argmax(y_pred_nn, axis=1)  # Predicted class labels\n",
    "        y_test_labels = np.argmax(y_test, axis=1)  # True class labels\n",
    "    else:\n",
    "        # Binary classification\n",
    "        y_pred_labels = (y_pred_nn > 0.5).astype(int)  # Predicted class labels\n",
    "        y_test_labels = y_test  # True class labels\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    nn_acc = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    \n",
    "    # Calculate ROC-AUC\n",
    "    if num_classes > 1:\n",
    "        # Multiclass ROC-AUC\n",
    "        nn_roc_auc = roc_auc_score(y_test, y_pred_nn, multi_class='ovr', average='weighted')\n",
    "    else:\n",
    "        # Binary ROC-AUC\n",
    "        nn_roc_auc = roc_auc_score(y_test_labels, y_pred_nn)\n",
    "    \n",
    "    # Store results\n",
    "    results.append({\n",
    "        \"dataset\": dataset[\"name\"],\n",
    "        \"accuracy\": nn_acc,\n",
    "        \"roc_auc\": nn_roc_auc\n",
    "    })\n",
    "    \n",
    "    print(f\"Model Accuracy: {nn_acc}\")\n",
    "    print(f\"ROC-AUC: {nn_roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f357bfaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Plot Accuracy for all datasets\n",
    "dataset_names = [result[\"dataset\"] for result in results]\n",
    "accuracies = [result[\"accuracy\"] for result in results]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(dataset_names, accuracies, color='blue')\n",
    "plt.xlabel(\"Dataset\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Model Accuracy across Datasets\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6af65a9",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved as HTML file at: model_accuracy_plot.html\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score\n",
    "\n",
    "# Assuming 'results' contains your dataset and accuracy information\n",
    "dataset_names = [result[\"dataset\"] for result in results]\n",
    "accuracies = [result[\"accuracy\"] for result in results]\n",
    "\n",
    "# Create the bar plot using Plotly\n",
    "fig = go.Figure(data=[go.Bar(x=dataset_names, y=accuracies, marker=dict(color='blue'))])\n",
    "\n",
    "# Add labels and title\n",
    "fig.update_layout(\n",
    "    title=\"Model Accuracy across Datasets\",\n",
    "    xaxis_title=\"Dataset\",\n",
    "    yaxis_title=\"Accuracy\",\n",
    "    xaxis_tickangle=-45\n",
    ")\n",
    "\n",
    "# Save the plot as an HTML file\n",
    "html_file_path = 'model_accuracy_plot.html'\n",
    "fig.write_html(html_file_path)\n",
    "\n",
    "# Print the file path to confirm where it's saved\n",
    "print(f\"Plot saved as HTML file at: {html_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd86ff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c824d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
